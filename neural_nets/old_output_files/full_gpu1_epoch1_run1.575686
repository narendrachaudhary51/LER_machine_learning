2018-02-02 18:11:45.691927: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-02 18:11:45.692038: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-02 18:11:45.692056: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-02-02 18:11:45.692067: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-02-02 18:11:45.692076: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-02-02 18:11:45.981573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.6405
pciBusID 0000:83:00.0
Total memory: 11.92GiB
Free memory: 11.82GiB
2018-02-02 18:11:45.981667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 
2018-02-02 18:11:45.981707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y 
2018-02-02 18:11:45.981750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:83:00.0)
2018-02-02 18:12:07.518188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:83:00.0)
2018-02-02 18:12:13.145281: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.12GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
[name: "/cpu:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 5901142669895518005
, name: "/gpu:0"
device_type: "GPU"
memory_limit: 12056245044
locality {
  bus_id: 2
}
incarnation: 10716605086176859770
physical_device_desc: "device: 0, name: Tesla K80, pci bus id: 0000:83:00.0"
]
Validation_count:  288
Validation data shape:  (288, 1024, 64, 1)
Validation labels shape:  (288, 1024, 64, 1)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 1024, 64, 64)      640       
_________________________________________________________________
batch_normalization_1 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_1 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_2 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_2 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_3 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_3 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_4 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_4 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_5 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_5 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_6 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_6 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_7 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_7 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_8 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_8 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_9 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_9 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_10 (Batc (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_10 (Dropout)         (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_11 (Batc (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_11 (Dropout)         (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_12 (Batc (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_12 (Dropout)         (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_13 (Batc (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_13 (Dropout)         (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_14 (Batc (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_14 (Dropout)         (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_15 (Batc (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_15 (Dropout)         (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_16 (Conv2D)           (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_16 (Batc (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_16 (Dropout)         (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 1024, 64, 1)       577       
=================================================================
Total params: 559,233
Trainable params: 557,185
Non-trainable params: 2,048
_________________________________________________________________
Xi set, Training count : 6 2880
Train on 2880 samples, validate on 288 samples
Epoch 1/1

   8/2880 [..............................] - ETA: 48:43 - loss: 2.6782
  16/2880 [..............................] - ETA: 33:32 - loss: 2.6071
  24/2880 [..............................] - ETA: 28:26 - loss: 2.4027
  32/2880 [..............................] - ETA: 25:52 - loss: 2.2433
  40/2880 [..............................] - ETA: 24:18 - loss: 2.1114
  48/2880 [..............................] - ETA: 23:15 - loss: 2.0007
  56/2880 [..............................] - ETA: 22:28 - loss: 1.9051
  64/2880 [..............................] - ETA: 21:53 - loss: 1.8222
  72/2880 [..............................] - ETA: 21:24 - loss: 1.7479
  80/2880 [..............................] - ETA: 21:01 - loss: 1.6814
  88/2880 [..............................] - ETA: 20:41 - loss: 1.6214
  96/2880 [>.............................] - ETA: 20:25 - loss: 1.5664
 104/2880 [>.............................] - ETA: 20:10 - loss: 1.5167
 112/2880 [>.............................] - ETA: 19:57 - loss: 1.4706
 120/2880 [>.............................] - ETA: 19:46 - loss: 1.4284
 128/2880 [>.............................] - ETA: 19:35 - loss: 1.3890
 136/2880 [>.............................] - ETA: 19:25 - loss: 1.3524
 144/2880 [>.............................] - ETA: 19:16 - loss: 1.3177
 152/2880 [>.............................] - ETA: 19:08 - loss: 1.2855
 160/2880 [>.............................] - ETA: 19:00 - loss: 1.2550
 168/2880 [>.............................] - ETA: 18:53 - loss: 1.2258
 176/2880 [>.............................] - ETA: 18:46 - loss: 1.1980
 184/2880 [>.............................] - ETA: 18:39 - loss: 1.1713
 192/2880 [=>............................] - ETA: 18:33 - loss: 1.1457
 200/2880 [=>............................] - ETA: 18:27 - loss: 1.1210
 208/2880 [=>............................] - ETA: 18:21 - loss: 1.0969
 216/2880 [=>............................] - ETA: 18:15 - loss: 1.0734
 224/2880 [=>............................] - ETA: 18:10 - loss: 1.0507
 232/2880 [=>............................] - ETA: 18:04 - loss: 1.0287
 240/2880 [=>............................] - ETA: 17:59 - loss: 1.0074
 248/2880 [=>............................] - ETA: 17:54 - loss: 0.9867
 256/2880 [=>............................] - ETA: 17:49 - loss: 0.9664
 264/2880 [=>............................] - ETA: 17:45 - loss: 0.9469
 272/2880 [=>............................] - ETA: 17:40 - loss: 0.9281
 280/2880 [=>............................] - ETA: 17:35 - loss: 0.9098
 288/2880 [==>...........................] - ETA: 17:31 - loss: 0.8924
 296/2880 [==>...........................] - ETA: 17:26 - loss: 0.8755
 304/2880 [==>...........................] - ETA: 17:22 - loss: 0.8592
 312/2880 [==>...........................] - ETA: 17:17 - loss: 0.8435
 320/2880 [==>...........................] - ETA: 17:13 - loss: 0.8284
 328/2880 [==>...........................] - ETA: 17:09 - loss: 0.8138
 336/2880 [==>...........................] - ETA: 17:05 - loss: 0.7998
 344/2880 [==>...........................] - ETA: 17:01 - loss: 0.7863
 352/2880 [==>...........................] - ETA: 16:57 - loss: 0.7732
 360/2880 [==>...........................] - ETA: 16:53 - loss: 0.7607
 368/2880 [==>...........................] - ETA: 16:49 - loss: 0.7485
 376/2880 [==>...........................] - ETA: 16:45 - loss: 0.7368
 384/2880 [===>..........................] - ETA: 16:41 - loss: 0.7255
 392/2880 [===>..........................] - ETA: 16:37 - loss: 0.7146
 400/2880 [===>..........................] - ETA: 16:33 - loss: 0.7040
 408/2880 [===>..........................] - ETA: 16:29 - loss: 0.6938
 416/2880 [===>..........................] - ETA: 16:26 - loss: 0.6839
 424/2880 [===>..........................] - ETA: 16:22 - loss: 0.6744
 432/2880 [===>..........................] - ETA: 16:18 - loss: 0.6652
 440/2880 [===>..........................] - ETA: 16:15 - loss: 0.6562
 448/2880 [===>..........................] - ETA: 16:11 - loss: 0.6475
 456/2880 [===>..........................] - ETA: 16:07 - loss: 0.6390
 464/2880 [===>..........................] - ETA: 16:03 - loss: 0.6309
 472/2880 [===>..........................] - ETA: 16:00 - loss: 0.6229
 480/2880 [====>.........................] - ETA: 15:56 - loss: 0.6152
 488/2880 [====>.........................] - ETA: 15:53 - loss: 0.6077
 496/2880 [====>.........................] - ETA: 15:49 - loss: 0.6004
 504/2880 [====>.........................] - ETA: 15:45 - loss: 0.5933
 512/2880 [====>.........................] - ETA: 15:42 - loss: 0.5863
 520/2880 [====>.........................] - ETA: 15:38 - loss: 0.5796
 528/2880 [====>.........................] - ETA: 15:35 - loss: 0.5730
 536/2880 [====>.........................] - ETA: 15:31 - loss: 0.5666
 544/2880 [====>.........................] - ETA: 15:28 - loss: 0.5604
 552/2880 [====>.........................] - ETA: 15:24 - loss: 0.5543
 560/2880 [====>.........................] - ETA: 15:21 - loss: 0.5483
 568/2880 [====>.........................] - ETA: 15:17 - loss: 0.5426
 576/2880 [=====>........................] - ETA: 15:14 - loss: 0.5369
 584/2880 [=====>........................] - ETA: 15:10 - loss: 0.5313
 592/2880 [=====>........................] - ETA: 15:07 - loss: 0.5259
 600/2880 [=====>........................] - ETA: 15:04 - loss: 0.5206
 608/2880 [=====>........................] - ETA: 15:00 - loss: 0.5154
 616/2880 [=====>........................] - ETA: 14:57 - loss: 0.5104
 624/2880 [=====>........................] - ETA: 14:53 - loss: 0.5054
 632/2880 [=====>........................] - ETA: 14:50 - loss: 0.5005
 640/2880 [=====>........................] - ETA: 14:47 - loss: 0.4958
 648/2880 [=====>........................] - ETA: 14:43 - loss: 0.4911
 656/2880 [=====>........................] - ETA: 14:40 - loss: 0.4865
 664/2880 [=====>........................] - ETA: 14:37 - loss: 0.4821
 672/2880 [======>.......................] - ETA: 14:33 - loss: 0.4777
 680/2880 [======>.......................] - ETA: 14:30 - loss: 0.4734
 688/2880 [======>.......................] - ETA: 14:27 - loss: 0.4692
 696/2880 [======>.......................] - ETA: 14:23 - loss: 0.4650
 704/2880 [======>.......................] - ETA: 14:20 - loss: 0.4610
 712/2880 [======>.......................] - ETA: 14:17 - loss: 0.4570
 720/2880 [======>.......................] - ETA: 14:13 - loss: 0.4531
 728/2880 [======>.......................] - ETA: 14:10 - loss: 0.4492
 736/2880 [======>.......................] - ETA: 14:07 - loss: 0.4455
 744/2880 [======>.......................] - ETA: 14:03 - loss: 0.4418
 752/2880 [======>.......................] - ETA: 14:00 - loss: 0.4381
 760/2880 [======>.......................] - ETA: 13:57 - loss: 0.4345
 768/2880 [=======>......................] - ETA: 13:53 - loss: 0.4310
 776/2880 [=======>......................] - ETA: 13:50 - loss: 0.4276
 784/2880 [=======>......................] - ETA: 13:47 - loss: 0.4241
 792/2880 [=======>......................] - ETA: 13:43 - loss: 0.4208
 800/2880 [=======>......................] - ETA: 13:40 - loss: 0.4175
 808/2880 [=======>......................] - ETA: 13:37 - loss: 0.4143
 816/2880 [=======>......................] - ETA: 13:34 - loss: 0.4110
 824/2880 [=======>......................] - ETA: 13:30 - loss: 0.4079
 832/2880 [=======>......................] - ETA: 13:27 - loss: 0.4048
 840/2880 [=======>......................] - ETA: 13:24 - loss: 0.4018
 848/2880 [=======>......................] - ETA: 13:20 - loss: 0.3988
 856/2880 [=======>......................] - ETA: 13:17 - loss: 0.3958
 864/2880 [========>.....................] - ETA: 13:14 - loss: 0.3929
 872/2880 [========>.....................] - ETA: 13:11 - loss: 0.3900
 880/2880 [========>.....................] - ETA: 13:07 - loss: 0.3872
 888/2880 [========>.....................] - ETA: 13:04 - loss: 0.3844
 896/2880 [========>.....................] - ETA: 13:01 - loss: 0.3817
 904/2880 [========>.....................] - ETA: 12:58 - loss: 0.3790
 912/2880 [========>.....................] - ETA: 12:54 - loss: 0.3763
 920/2880 [========>.....................] - ETA: 12:51 - loss: 0.3737
 928/2880 [========>.....................] - ETA: 12:48 - loss: 0.3711
 936/2880 [========>.....................] - ETA: 12:45 - loss: 0.3685
 944/2880 [========>.....................] - ETA: 12:42 - loss: 0.3660
 952/2880 [========>.....................] - ETA: 12:38 - loss: 0.3635
 960/2880 [=========>....................] - ETA: 12:35 - loss: 0.3611
 968/2880 [=========>....................] - ETA: 12:32 - loss: 0.3586
 976/2880 [=========>....................] - ETA: 12:29 - loss: 0.3563
 984/2880 [=========>....................] - ETA: 12:25 - loss: 0.3539
 992/2880 [=========>....................] - ETA: 12:22 - loss: 0.3516
1000/2880 [=========>....................] - ETA: 12:19 - loss: 0.3493
1008/2880 [=========>....................] - ETA: 12:16 - loss: 0.3470
1016/2880 [=========>....................] - ETA: 12:12 - loss: 0.3448
1024/2880 [=========>....................] - ETA: 12:09 - loss: 0.3426
1032/2880 [=========>....................] - ETA: 12:06 - loss: 0.3404
1040/2880 [=========>....................] - ETA: 12:03 - loss: 0.3382
1048/2880 [=========>....................] - ETA: 12:00 - loss: 0.3361
1056/2880 [==========>...................] - ETA: 11:56 - loss: 0.3340
1064/2880 [==========>...................] - ETA: 11:53 - loss: 0.3319
1072/2880 [==========>...................] - ETA: 11:50 - loss: 0.3299
1080/2880 [==========>...................] - ETA: 11:47 - loss: 0.3279
1088/2880 [==========>...................] - ETA: 11:44 - loss: 0.3259
1096/2880 [==========>...................] - ETA: 11:40 - loss: 0.3239
1104/2880 [==========>...................] - ETA: 11:37 - loss: 0.3219
1112/2880 [==========>...................] - ETA: 11:34 - loss: 0.3200
1120/2880 [==========>...................] - ETA: 11:31 - loss: 0.3181
1128/2880 [==========>...................] - ETA: 11:28 - loss: 0.3162
1136/2880 [==========>...................] - ETA: 11:24 - loss: 0.3144
1144/2880 [==========>...................] - ETA: 11:21 - loss: 0.3125
1152/2880 [===========>..................] - ETA: 11:18 - loss: 0.3107
1160/2880 [===========>..................] - ETA: 11:15 - loss: 0.3089
1168/2880 [===========>..................] - ETA: 11:12 - loss: 0.3071
1176/2880 [===========>..................] - ETA: 11:08 - loss: 0.3053
1184/2880 [===========>..................] - ETA: 11:05 - loss: 0.3036
1192/2880 [===========>..................] - ETA: 11:02 - loss: 0.3019
1200/2880 [===========>..................] - ETA: 10:59 - loss: 0.3002
1208/2880 [===========>..................] - ETA: 10:56 - loss: 0.2985
1216/2880 [===========>..................] - ETA: 10:53 - loss: 0.2968
1224/2880 [===========>..................] - ETA: 10:49 - loss: 0.2952
1232/2880 [===========>..................] - ETA: 10:46 - loss: 0.2935
1240/2880 [===========>..................] - ETA: 10:43 - loss: 0.2919
1248/2880 [============>.................] - ETA: 10:40 - loss: 0.2903
1256/2880 [============>.................] - ETA: 10:37 - loss: 0.2888
1264/2880 [============>.................] - ETA: 10:33 - loss: 0.2872
1272/2880 [============>.................] - ETA: 10:30 - loss: 0.2856
1280/2880 [============>.................] - ETA: 10:27 - loss: 0.2841
1288/2880 [============>.................] - ETA: 10:24 - loss: 0.2826
1296/2880 [============>.................] - ETA: 10:21 - loss: 0.2811
1304/2880 [============>.................] - ETA: 10:18 - loss: 0.2796
1312/2880 [============>.................] - ETA: 10:14 - loss: 0.2781
1320/2880 [============>.................] - ETA: 10:11 - loss: 0.2766
1328/2880 [============>.................] - ETA: 10:08 - loss: 0.2752
1336/2880 [============>.................] - ETA: 10:05 - loss: 0.2738
1344/2880 [=============>................] - ETA: 10:02 - loss: 0.2723
1352/2880 [=============>................] - ETA: 9:59 - loss: 0.2709 
1360/2880 [=============>................] - ETA: 9:55 - loss: 0.2695
1368/2880 [=============>................] - ETA: 9:52 - loss: 0.2682
1376/2880 [=============>................] - ETA: 9:49 - loss: 0.2668
1384/2880 [=============>................] - ETA: 9:46 - loss: 0.2655
1392/2880 [=============>................] - ETA: 9:43 - loss: 0.2641
1400/2880 [=============>................] - ETA: 9:40 - loss: 0.2628
1408/2880 [=============>................] - ETA: 9:36 - loss: 0.2615
1416/2880 [=============>................] - ETA: 9:33 - loss: 0.2602
1424/2880 [=============>................] - ETA: 9:30 - loss: 0.2589
1432/2880 [=============>................] - ETA: 9:27 - loss: 0.2576
1440/2880 [==============>...............] - ETA: 9:24 - loss: 0.2564
1448/2880 [==============>...............] - ETA: 9:21 - loss: 0.2551
1456/2880 [==============>...............] - ETA: 9:17 - loss: 0.2539
1464/2880 [==============>...............] - ETA: 9:14 - loss: 0.2527
1472/2880 [==============>...............] - ETA: 9:11 - loss: 0.2514
1480/2880 [==============>...............] - ETA: 9:08 - loss: 0.2502
1488/2880 [==============>...............] - ETA: 9:05 - loss: 0.2490
1496/2880 [==============>...............] - ETA: 9:02 - loss: 0.2479
1504/2880 [==============>...............] - ETA: 8:58 - loss: 0.2467
1512/2880 [==============>...............] - ETA: 8:55 - loss: 0.2455
1520/2880 [==============>...............] - ETA: 8:52 - loss: 0.2444
1528/2880 [==============>...............] - ETA: 8:49 - loss: 0.2432
1536/2880 [===============>..............] - ETA: 8:46 - loss: 0.2421
1544/2880 [===============>..............] - ETA: 8:43 - loss: 0.2410
1552/2880 [===============>..............] - ETA: 8:39 - loss: 0.2399
1560/2880 [===============>..............] - ETA: 8:36 - loss: 0.2388
1568/2880 [===============>..............] - ETA: 8:33 - loss: 0.2377
1576/2880 [===============>..............] - ETA: 8:30 - loss: 0.2366
1584/2880 [===============>..............] - ETA: 8:27 - loss: 0.2355
1592/2880 [===============>..............] - ETA: 8:24 - loss: 0.2344
1600/2880 [===============>..............] - ETA: 8:21 - loss: 0.2334
1608/2880 [===============>..............] - ETA: 8:17 - loss: 0.2323
1616/2880 [===============>..............] - ETA: 8:14 - loss: 0.2313
1624/2880 [===============>..............] - ETA: 8:11 - loss: 0.2303
1632/2880 [================>.............] - ETA: 8:08 - loss: 0.2293
1640/2880 [================>.............] - ETA: 8:05 - loss: 0.2283
1648/2880 [================>.............] - ETA: 8:02 - loss: 0.2273
1656/2880 [================>.............] - ETA: 7:59 - loss: 0.2263
1664/2880 [================>.............] - ETA: 7:55 - loss: 0.2253
1672/2880 [================>.............] - ETA: 7:52 - loss: 0.2243
1680/2880 [================>.............] - ETA: 7:49 - loss: 0.2233
1688/2880 [================>.............] - ETA: 7:46 - loss: 0.2224
1696/2880 [================>.............] - ETA: 7:43 - loss: 0.2214
1704/2880 [================>.............] - ETA: 7:40 - loss: 0.2205
1712/2880 [================>.............] - ETA: 7:37 - loss: 0.2196
1720/2880 [================>.............] - ETA: 7:33 - loss: 0.2186
1728/2880 [=================>............] - ETA: 7:30 - loss: 0.2177
1736/2880 [=================>............] - ETA: 7:27 - loss: 0.2168
1744/2880 [=================>............] - ETA: 7:24 - loss: 0.2159
1752/2880 [=================>............] - ETA: 7:21 - loss: 0.2150
1760/2880 [=================>............] - ETA: 7:18 - loss: 0.2141
1768/2880 [=================>............] - ETA: 7:14 - loss: 0.2132
1776/2880 [=================>............] - ETA: 7:11 - loss: 0.2123
1784/2880 [=================>............] - ETA: 7:08 - loss: 0.2115
1792/2880 [=================>............] - ETA: 7:05 - loss: 0.2106
1800/2880 [=================>............] - ETA: 7:02 - loss: 0.2097
1808/2880 [=================>............] - ETA: 6:59 - loss: 0.2089
1816/2880 [=================>............] - ETA: 6:56 - loss: 0.2081
1824/2880 [==================>...........] - ETA: 6:53 - loss: 0.2072
1832/2880 [==================>...........] - ETA: 6:49 - loss: 0.2064
1840/2880 [==================>...........] - ETA: 6:46 - loss: 0.2056
1848/2880 [==================>...........] - ETA: 6:43 - loss: 0.2047
1856/2880 [==================>...........] - ETA: 6:40 - loss: 0.2039
1864/2880 [==================>...........] - ETA: 6:37 - loss: 0.2031
1872/2880 [==================>...........] - ETA: 6:34 - loss: 0.2023
1880/2880 [==================>...........] - ETA: 6:31 - loss: 0.2015
1888/2880 [==================>...........] - ETA: 6:27 - loss: 0.2007
1896/2880 [==================>...........] - ETA: 6:24 - loss: 0.2000
1904/2880 [==================>...........] - ETA: 6:21 - loss: 0.1992
1912/2880 [==================>...........] - ETA: 6:18 - loss: 0.1984
1920/2880 [===================>..........] - ETA: 6:15 - loss: 0.1977
1928/2880 [===================>..........] - ETA: 6:12 - loss: 0.1969
1936/2880 [===================>..........] - ETA: 6:09 - loss: 0.1962
1944/2880 [===================>..........] - ETA: 6:05 - loss: 0.1954
1952/2880 [===================>..........] - ETA: 6:02 - loss: 0.1947
1960/2880 [===================>..........] - ETA: 5:59 - loss: 0.1939
1968/2880 [===================>..........] - ETA: 5:56 - loss: 0.1932
1976/2880 [===================>..........] - ETA: 5:53 - loss: 0.1925
1984/2880 [===================>..........] - ETA: 5:50 - loss: 0.1918
1992/2880 [===================>..........] - ETA: 5:47 - loss: 0.1911
2000/2880 [===================>..........] - ETA: 5:43 - loss: 0.1903
2008/2880 [===================>..........] - ETA: 5:40 - loss: 0.1896
2016/2880 [====================>.........] - ETA: 5:37 - loss: 0.1889
2024/2880 [====================>.........] - ETA: 5:34 - loss: 0.1883
2032/2880 [====================>.........] - ETA: 5:31 - loss: 0.1876
2040/2880 [====================>.........] - ETA: 5:28 - loss: 0.1869
2048/2880 [====================>.........] - ETA: 5:25 - loss: 0.1862
2056/2880 [====================>.........] - ETA: 5:22 - loss: 0.1855
2064/2880 [====================>.........] - ETA: 5:18 - loss: 0.1849
2072/2880 [====================>.........] - ETA: 5:15 - loss: 0.1842
2080/2880 [====================>.........] - ETA: 5:12 - loss: 0.1835
2088/2880 [====================>.........] - ETA: 5:09 - loss: 0.1829
2096/2880 [====================>.........] - ETA: 5:06 - loss: 0.1822
2104/2880 [====================>.........] - ETA: 5:03 - loss: 0.1816
2112/2880 [=====================>........] - ETA: 5:00 - loss: 0.1810
2120/2880 [=====================>........] - ETA: 4:56 - loss: 0.1803
2128/2880 [=====================>........] - ETA: 4:53 - loss: 0.1797
2136/2880 [=====================>........] - ETA: 4:50 - loss: 0.1791
2144/2880 [=====================>........] - ETA: 4:47 - loss: 0.1784
2152/2880 [=====================>........] - ETA: 4:44 - loss: 0.1778
2160/2880 [=====================>........] - ETA: 4:41 - loss: 0.1772
2168/2880 [=====================>........] - ETA: 4:38 - loss: 0.1766
2176/2880 [=====================>........] - ETA: 4:35 - loss: 0.1760
2184/2880 [=====================>........] - ETA: 4:31 - loss: 0.1754
2192/2880 [=====================>........] - ETA: 4:28 - loss: 0.1748
2200/2880 [=====================>........] - ETA: 4:25 - loss: 0.1742
2208/2880 [======================>.......] - ETA: 4:22 - loss: 0.1736
2216/2880 [======================>.......] - ETA: 4:19 - loss: 0.1730
2224/2880 [======================>.......] - ETA: 4:16 - loss: 0.1724
2232/2880 [======================>.......] - ETA: 4:13 - loss: 0.1718
2240/2880 [======================>.......] - ETA: 4:09 - loss: 0.1713
2248/2880 [======================>.......] - ETA: 4:06 - loss: 0.1707
2256/2880 [======================>.......] - ETA: 4:03 - loss: 0.1701
2264/2880 [======================>.......] - ETA: 4:00 - loss: 0.1696
2272/2880 [======================>.......] - ETA: 3:57 - loss: 0.1690
2280/2880 [======================>.......] - ETA: 3:54 - loss: 0.1684
2288/2880 [======================>.......] - ETA: 3:51 - loss: 0.1679
2296/2880 [======================>.......] - ETA: 3:48 - loss: 0.1673
2304/2880 [=======================>......] - ETA: 3:44 - loss: 0.1668
2312/2880 [=======================>......] - ETA: 3:41 - loss: 0.1663
2320/2880 [=======================>......] - ETA: 3:38 - loss: 0.1657
2328/2880 [=======================>......] - ETA: 3:35 - loss: 0.1652
2336/2880 [=======================>......] - ETA: 3:32 - loss: 0.1647
2344/2880 [=======================>......] - ETA: 3:29 - loss: 0.1641
2352/2880 [=======================>......] - ETA: 3:26 - loss: 0.1636
2360/2880 [=======================>......] - ETA: 3:23 - loss: 0.1631
2368/2880 [=======================>......] - ETA: 3:19 - loss: 0.1626
2376/2880 [=======================>......] - ETA: 3:16 - loss: 0.1621
2384/2880 [=======================>......] - ETA: 3:13 - loss: 0.1615
2392/2880 [=======================>......] - ETA: 3:10 - loss: 0.1610
2400/2880 [========================>.....] - ETA: 3:07 - loss: 0.1605
2408/2880 [========================>.....] - ETA: 3:04 - loss: 0.1600
2416/2880 [========================>.....] - ETA: 3:01 - loss: 0.1595
2424/2880 [========================>.....] - ETA: 2:58 - loss: 0.1590
2432/2880 [========================>.....] - ETA: 2:54 - loss: 0.1585
2440/2880 [========================>.....] - ETA: 2:51 - loss: 0.1580
2448/2880 [========================>.....] - ETA: 2:48 - loss: 0.1576
2456/2880 [========================>.....] - ETA: 2:45 - loss: 0.1571
2464/2880 [========================>.....] - ETA: 2:42 - loss: 0.1566
2472/2880 [========================>.....] - ETA: 2:39 - loss: 0.1561
2480/2880 [========================>.....] - ETA: 2:36 - loss: 0.1557
2488/2880 [========================>.....] - ETA: 2:33 - loss: 0.1552
2496/2880 [=========================>....] - ETA: 2:29 - loss: 0.1547
2504/2880 [=========================>....] - ETA: 2:26 - loss: 0.1542
2512/2880 [=========================>....] - ETA: 2:23 - loss: 0.1538
2520/2880 [=========================>....] - ETA: 2:20 - loss: 0.1533
2528/2880 [=========================>....] - ETA: 2:17 - loss: 0.1529
2536/2880 [=========================>....] - ETA: 2:14 - loss: 0.1524
2544/2880 [=========================>....] - ETA: 2:11 - loss: 0.1520
2552/2880 [=========================>....] - ETA: 2:08 - loss: 0.1515
2560/2880 [=========================>....] - ETA: 2:04 - loss: 0.1511
2568/2880 [=========================>....] - ETA: 2:01 - loss: 0.1506
2576/2880 [=========================>....] - ETA: 1:58 - loss: 0.1502
2584/2880 [=========================>....] - ETA: 1:55 - loss: 0.1497
2592/2880 [==========================>...] - ETA: 1:52 - loss: 0.1493
2600/2880 [==========================>...] - ETA: 1:49 - loss: 0.1489
2608/2880 [==========================>...] - ETA: 1:46 - loss: 0.1485
2616/2880 [==========================>...] - ETA: 1:43 - loss: 0.1480
2624/2880 [==========================>...] - ETA: 1:39 - loss: 0.1476
2632/2880 [==========================>...] - ETA: 1:36 - loss: 0.1472
2640/2880 [==========================>...] - ETA: 1:33 - loss: 0.1468
2648/2880 [==========================>...] - ETA: 1:30 - loss: 0.1463
2656/2880 [==========================>...] - ETA: 1:27 - loss: 0.1459
2664/2880 [==========================>...] - ETA: 1:24 - loss: 0.1455
2672/2880 [==========================>...] - ETA: 1:21 - loss: 0.1451
2680/2880 [==========================>...] - ETA: 1:18 - loss: 0.1447
2688/2880 [===========================>..] - ETA: 1:14 - loss: 0.1443
2696/2880 [===========================>..] - ETA: 1:11 - loss: 0.1439
2704/2880 [===========================>..] - ETA: 1:08 - loss: 0.1435
2712/2880 [===========================>..] - ETA: 1:05 - loss: 0.1431
2720/2880 [===========================>..] - ETA: 1:02 - loss: 0.1427
2728/2880 [===========================>..] - ETA: 59s - loss: 0.1423 
2736/2880 [===========================>..] - ETA: 56s - loss: 0.1419
2744/2880 [===========================>..] - ETA: 53s - loss: 0.1415
2752/2880 [===========================>..] - ETA: 49s - loss: 0.1411
2760/2880 [===========================>..] - ETA: 46s - loss: 0.1408
2768/2880 [===========================>..] - ETA: 43s - loss: 0.1404
2776/2880 [===========================>..] - ETA: 40s - loss: 0.1400
2784/2880 [============================>.] - ETA: 37s - loss: 0.1396
2792/2880 [============================>.] - ETA: 34s - loss: 0.1392
2800/2880 [============================>.] - ETA: 31s - loss: 0.1389
2808/2880 [============================>.] - ETA: 28s - loss: 0.1385
2816/2880 [============================>.] - ETA: 24s - loss: 0.1381
2824/2880 [============================>.] - ETA: 21s - loss: 0.1378
2832/2880 [============================>.] - ETA: 18s - loss: 0.1374
2840/2880 [============================>.] - ETA: 15s - loss: 0.1370
2848/2880 [============================>.] - ETA: 12s - loss: 0.1367
2856/2880 [============================>.] - ETA: 9s - loss: 0.1363 
2864/2880 [============================>.] - ETA: 6s - loss: 0.1359
2872/2880 [============================>.] - ETA: 3s - loss: 0.1356
2880/2880 [==============================] - 1156s 401ms/step - loss: 0.1352 - val_loss: 0.0160
/scratch/user/narendra5/.conda/envs/deeplearning/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
Using TensorFlow backend.
Traceback (most recent call last):
  File "/scratch/user/narendra5/LER_machine_learning/neural_nets/nnet.py", line 194, in <module>
    X_train[count] = imnoisy
ValueError: could not broadcast input array from shape (1024,64) into shape (1024,64,1)
