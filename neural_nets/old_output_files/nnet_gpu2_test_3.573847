2018-01-30 16:06:42.702219: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-30 16:06:42.704454: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-30 16:06:42.704478: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-01-30 16:06:42.704500: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-01-30 16:06:42.704509: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-01-30 16:06:42.987905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.6405
pciBusID 0000:83:00.0
Total memory: 11.92GiB
Free memory: 11.82GiB
2018-01-30 16:06:43.204291: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x5652c6816460 exists before initializing the StreamExecutor. We haven't verified StreamExecutor works with that.
2018-01-30 16:06:43.207322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.6405
pciBusID 0000:84:00.0
Total memory: 11.92GiB
Free memory: 11.83GiB
2018-01-30 16:06:43.207607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1 
2018-01-30 16:06:43.207641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y 
2018-01-30 16:06:43.207654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y 
2018-01-30 16:06:43.207688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:83:00.0)
2018-01-30 16:06:43.207701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:84:00.0)
2018-01-30 16:07:42.733313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:83:00.0)
2018-01-30 16:07:42.735847: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:84:00.0)
2018-01-30 16:07:51.267142: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.12GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-01-30 16:07:51.269319: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_1_bfc) ran out of memory trying to allocate 1.12GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
[name: "/cpu:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 9352703448546478068
, name: "/gpu:0"
device_type: "GPU"
memory_limit: 12056245044
locality {
  bus_id: 2
}
incarnation: 10257065859270600960
physical_device_desc: "device: 0, name: Tesla K80, pci bus id: 0000:83:00.0"
, name: "/gpu:1"
device_type: "GPU"
memory_limit: 12071187252
locality {
  bus_id: 2
}
incarnation: 13113180655707205551
physical_device_desc: "device: 1, name: Tesla K80, pci bus id: 0000:84:00.0"
]
Training count:  8928
Validation count:  288
float64
Train data shape:  (8928, 1024, 64, 1)
Train labels shape:  (8928, 1024, 64, 1)
Validation data shape:  (288, 1024, 64, 1)
Validation labels shape:  (288, 1024, 64, 1)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 1024, 64, 64)      640       
_________________________________________________________________
batch_normalization_1 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_1 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_2 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_2 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_3 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_3 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_4 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_4 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_5 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_5 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_6 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_6 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_7 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_7 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_8 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_8 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_9 (Batch (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_9 (Dropout)          (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_10 (Batc (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_10 (Dropout)         (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_11 (Batc (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_11 (Dropout)         (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_12 (Batc (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_12 (Dropout)         (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_13 (Batc (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_13 (Dropout)         (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_14 (Batc (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_14 (Dropout)         (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_15 (Batc (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_15 (Dropout)         (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_16 (Conv2D)           (None, 1024, 64, 64)      36928     
_________________________________________________________________
batch_normalization_16 (Batc (None, 1024, 64, 64)      256       
_________________________________________________________________
dropout_16 (Dropout)         (None, 1024, 64, 64)      0         
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 1024, 64, 1)       577       
=================================================================
Total params: 559,233
Trainable params: 557,185
Non-trainable params: 2,048
_________________________________________________________________
Train on 8928 samples, validate on 288 samples
Epoch 1/1

  16/8928 [..............................] - ETA: 1:42:46 - loss: 2.6778
  32/8928 [..............................] - ETA: 1:05:48 - loss: 2.4293
  48/8928 [..............................] - ETA: 53:26 - loss: 2.2219  
  64/8928 [..............................] - ETA: 47:13 - loss: 2.0470
  80/8928 [..............................] - ETA: 43:29 - loss: 1.9064
  96/8928 [..............................] - ETA: 40:59 - loss: 1.7965
 112/8928 [..............................] - ETA: 39:10 - loss: 1.6909
 128/8928 [..............................] - ETA: 37:49 - loss: 1.6063
 144/8928 [..............................] - ETA: 36:44 - loss: 1.5255
 160/8928 [..............................] - ETA: 35:50 - loss: 1.4571
 176/8928 [..............................] - ETA: 35:06 - loss: 1.3950
 192/8928 [..............................] - ETA: 34:28 - loss: 1.3379
 208/8928 [..............................] - ETA: 33:57 - loss: 1.2880
 224/8928 [..............................] - ETA: 33:30 - loss: 1.2414
 240/8928 [..............................] - ETA: 33:06 - loss: 1.1986
 256/8928 [..............................] - ETA: 32:44 - loss: 1.1600
 272/8928 [..............................] - ETA: 32:24 - loss: 1.1242
 288/8928 [..............................] - ETA: 32:06 - loss: 1.0911
 304/8928 [>.............................] - ETA: 31:51 - loss: 1.0607
 320/8928 [>.............................] - ETA: 31:36 - loss: 1.0323
 336/8928 [>.............................] - ETA: 31:23 - loss: 1.0057
 352/8928 [>.............................] - ETA: 31:10 - loss: 0.9813
 368/8928 [>.............................] - ETA: 30:58 - loss: 0.9581
 384/8928 [>.............................] - ETA: 30:47 - loss: 0.9361
 400/8928 [>.............................] - ETA: 30:37 - loss: 0.9155
 416/8928 [>.............................] - ETA: 30:27 - loss: 0.8964
 432/8928 [>.............................] - ETA: 30:18 - loss: 0.8781
 448/8928 [>.............................] - ETA: 30:09 - loss: 0.8608
 464/8928 [>.............................] - ETA: 30:01 - loss: 0.8447
 480/8928 [>.............................] - ETA: 29:53 - loss: 0.8293
 496/8928 [>.............................] - ETA: 29:45 - loss: 0.8146
 512/8928 [>.............................] - ETA: 29:37 - loss: 0.8007
 528/8928 [>.............................] - ETA: 29:30 - loss: 0.7875
 544/8928 [>.............................] - ETA: 29:23 - loss: 0.7748
 560/8928 [>.............................] - ETA: 29:16 - loss: 0.7628
 576/8928 [>.............................] - ETA: 29:10 - loss: 0.7512
 592/8928 [>.............................] - ETA: 29:03 - loss: 0.7402
 608/8928 [=>............................] - ETA: 28:57 - loss: 0.7295
 624/8928 [=>............................] - ETA: 28:51 - loss: 0.7193
 640/8928 [=>............................] - ETA: 28:45 - loss: 0.7096
 656/8928 [=>............................] - ETA: 28:39 - loss: 0.7002
 672/8928 [=>............................] - ETA: 28:33 - loss: 0.6912
 688/8928 [=>............................] - ETA: 28:28 - loss: 0.6826
 704/8928 [=>............................] - ETA: 28:22 - loss: 0.6742
 720/8928 [=>............................] - ETA: 28:17 - loss: 0.6661
 736/8928 [=>............................] - ETA: 28:12 - loss: 0.6583
 752/8928 [=>............................] - ETA: 28:07 - loss: 0.6508
 768/8928 [=>............................] - ETA: 28:02 - loss: 0.6435
 784/8928 [=>............................] - ETA: 27:57 - loss: 0.6365
 800/8928 [=>............................] - ETA: 27:52 - loss: 0.6296
 816/8928 [=>............................] - ETA: 27:47 - loss: 0.6229
 832/8928 [=>............................] - ETA: 27:42 - loss: 0.6164
 848/8928 [=>............................] - ETA: 27:38 - loss: 0.6102
 864/8928 [=>............................] - ETA: 27:33 - loss: 0.6041
 880/8928 [=>............................] - ETA: 27:28 - loss: 0.5981
 896/8928 [==>...........................] - ETA: 27:24 - loss: 0.5924
 912/8928 [==>...........................] - ETA: 27:19 - loss: 0.5868
 928/8928 [==>...........................] - ETA: 27:15 - loss: 0.5813
 944/8928 [==>...........................] - ETA: 27:11 - loss: 0.5760
 960/8928 [==>...........................] - ETA: 27:06 - loss: 0.5708
 976/8928 [==>...........................] - ETA: 27:02 - loss: 0.5656
 992/8928 [==>...........................] - ETA: 26:58 - loss: 0.5607
1008/8928 [==>...........................] - ETA: 26:54 - loss: 0.5558
1024/8928 [==>...........................] - ETA: 26:49 - loss: 0.5511
1040/8928 [==>...........................] - ETA: 26:45 - loss: 0.5464
1056/8928 [==>...........................] - ETA: 26:41 - loss: 0.5419
1072/8928 [==>...........................] - ETA: 26:37 - loss: 0.5374
1088/8928 [==>...........................] - ETA: 26:33 - loss: 0.5331
1104/8928 [==>...........................] - ETA: 26:29 - loss: 0.5288
1120/8928 [==>...........................] - ETA: 26:25 - loss: 0.5246
1136/8928 [==>...........................] - ETA: 26:20 - loss: 0.5206
1152/8928 [==>...........................] - ETA: 26:16 - loss: 0.5166
1168/8928 [==>...........................] - ETA: 26:12 - loss: 0.5126
1184/8928 [==>...........................] - ETA: 26:08 - loss: 0.5088
1200/8928 [===>..........................] - ETA: 26:04 - loss: 0.5050
1216/8928 [===>..........................] - ETA: 26:00 - loss: 0.5012
1232/8928 [===>..........................] - ETA: 25:56 - loss: 0.4976
1248/8928 [===>..........................] - ETA: 25:53 - loss: 0.4940
1264/8928 [===>..........................] - ETA: 25:49 - loss: 0.4904
1280/8928 [===>..........................] - ETA: 25:45 - loss: 0.4869
1296/8928 [===>..........................] - ETA: 25:41 - loss: 0.4835
1312/8928 [===>..........................] - ETA: 25:37 - loss: 0.4801
1328/8928 [===>..........................] - ETA: 25:33 - loss: 0.4768
1344/8928 [===>..........................] - ETA: 25:30 - loss: 0.4736
1360/8928 [===>..........................] - ETA: 25:26 - loss: 0.4703
1376/8928 [===>..........................] - ETA: 25:22 - loss: 0.4672
1392/8928 [===>..........................] - ETA: 25:18 - loss: 0.4640
1408/8928 [===>..........................] - ETA: 25:15 - loss: 0.4610
1424/8928 [===>..........................] - ETA: 25:11 - loss: 0.4580
1440/8928 [===>..........................] - ETA: 25:07 - loss: 0.4550
1456/8928 [===>..........................] - ETA: 25:03 - loss: 0.4520
1472/8928 [===>..........................] - ETA: 25:00 - loss: 0.4491
1488/8928 [====>.........................] - ETA: 24:56 - loss: 0.4463
1504/8928 [====>.........................] - ETA: 24:53 - loss: 0.4434
1520/8928 [====>.........................] - ETA: 24:49 - loss: 0.4407
1536/8928 [====>.........................] - ETA: 24:45 - loss: 0.4379
1552/8928 [====>.........................] - ETA: 24:42 - loss: 0.4352
1568/8928 [====>.........................] - ETA: 24:38 - loss: 0.4326
1584/8928 [====>.........................] - ETA: 24:34 - loss: 0.4299
1600/8928 [====>.........................] - ETA: 24:31 - loss: 0.4273
1616/8928 [====>.........................] - ETA: 24:27 - loss: 0.4247
1632/8928 [====>.........................] - ETA: 24:24 - loss: 0.4222
1648/8928 [====>.........................] - ETA: 24:20 - loss: 0.4197
1664/8928 [====>.........................] - ETA: 24:17 - loss: 0.4172
1680/8928 [====>.........................] - ETA: 24:13 - loss: 0.4147
1696/8928 [====>.........................] - ETA: 24:10 - loss: 0.4123
1712/8928 [====>.........................] - ETA: 24:06 - loss: 0.4099
1728/8928 [====>.........................] - ETA: 24:03 - loss: 0.4075
1744/8928 [====>.........................] - ETA: 23:59 - loss: 0.4052
1760/8928 [====>.........................] - ETA: 23:56 - loss: 0.4029
1776/8928 [====>.........................] - ETA: 23:52 - loss: 0.4006
1792/8928 [=====>........................] - ETA: 23:49 - loss: 0.3983
1808/8928 [=====>........................] - ETA: 23:45 - loss: 0.3961
1824/8928 [=====>........................] - ETA: 23:42 - loss: 0.3938
1840/8928 [=====>........................] - ETA: 23:38 - loss: 0.3917
1856/8928 [=====>........................] - ETA: 23:35 - loss: 0.3895
1872/8928 [=====>........................] - ETA: 23:31 - loss: 0.3873
1888/8928 [=====>........................] - ETA: 23:28 - loss: 0.3852
1904/8928 [=====>........................] - ETA: 23:24 - loss: 0.3831
1920/8928 [=====>........................] - ETA: 23:21 - loss: 0.3810
1936/8928 [=====>........................] - ETA: 23:17 - loss: 0.3790
1952/8928 [=====>........................] - ETA: 23:14 - loss: 0.3769
1968/8928 [=====>........................] - ETA: 23:11 - loss: 0.3749
1984/8928 [=====>........................] - ETA: 23:08 - loss: 0.3729
2000/8928 [=====>........................] - ETA: 23:04 - loss: 0.3709
2016/8928 [=====>........................] - ETA: 23:01 - loss: 0.3690
2032/8928 [=====>........................] - ETA: 22:57 - loss: 0.3670
2048/8928 [=====>........................] - ETA: 22:54 - loss: 0.3651
2064/8928 [=====>........................] - ETA: 22:50 - loss: 0.3632
2080/8928 [=====>........................] - ETA: 22:47 - loss: 0.3613
2096/8928 [======>.......................] - ETA: 22:44 - loss: 0.3594
2112/8928 [======>.......................] - ETA: 22:40 - loss: 0.3576
2128/8928 [======>.......................] - ETA: 22:37 - loss: 0.3557
2144/8928 [======>.......................] - ETA: 22:34 - loss: 0.3539
2160/8928 [======>.......................] - ETA: 22:30 - loss: 0.3521
2176/8928 [======>.......................] - ETA: 22:27 - loss: 0.3503
2192/8928 [======>.......................] - ETA: 22:24 - loss: 0.3486
2208/8928 [======>.......................] - ETA: 22:20 - loss: 0.3468
2224/8928 [======>.......................] - ETA: 22:17 - loss: 0.3451
2240/8928 [======>.......................] - ETA: 22:13 - loss: 0.3434
2256/8928 [======>.......................] - ETA: 22:10 - loss: 0.3417
2272/8928 [======>.......................] - ETA: 22:07 - loss: 0.3400
2288/8928 [======>.......................] - ETA: 22:03 - loss: 0.3383
2304/8928 [======>.......................] - ETA: 22:00 - loss: 0.3366
2320/8928 [======>.......................] - ETA: 21:57 - loss: 0.3350
2336/8928 [======>.......................] - ETA: 21:53 - loss: 0.3334
2352/8928 [======>.......................] - ETA: 21:50 - loss: 0.3317
2368/8928 [======>.......................] - ETA: 21:46 - loss: 0.3301
2384/8928 [=======>......................] - ETA: 21:43 - loss: 0.3285
2400/8928 [=======>......................] - ETA: 21:40 - loss: 0.3270
2416/8928 [=======>......................] - ETA: 21:36 - loss: 0.3254
2432/8928 [=======>......................] - ETA: 21:33 - loss: 0.3238
2448/8928 [=======>......................] - ETA: 21:30 - loss: 0.3223
2464/8928 [=======>......................] - ETA: 21:26 - loss: 0.3208
2480/8928 [=======>......................] - ETA: 21:23 - loss: 0.3193
2496/8928 [=======>......................] - ETA: 21:20 - loss: 0.3178
2512/8928 [=======>......................] - ETA: 21:17 - loss: 0.3163
2528/8928 [=======>......................] - ETA: 21:13 - loss: 0.3148
2544/8928 [=======>......................] - ETA: 21:10 - loss: 0.3133
2560/8928 [=======>......................] - ETA: 21:07 - loss: 0.3119
2576/8928 [=======>......................] - ETA: 21:03 - loss: 0.3104
2592/8928 [=======>......................] - ETA: 21:00 - loss: 0.3090
2608/8928 [=======>......................] - ETA: 20:57 - loss: 0.3076
2624/8928 [=======>......................] - ETA: 20:53 - loss: 0.3062
2640/8928 [=======>......................] - ETA: 20:50 - loss: 0.3048
2656/8928 [=======>......................] - ETA: 20:47 - loss: 0.3034
2672/8928 [=======>......................] - ETA: 20:43 - loss: 0.3020
2688/8928 [========>.....................] - ETA: 20:40 - loss: 0.3007
2704/8928 [========>.....................] - ETA: 20:37 - loss: 0.2993
2720/8928 [========>.....................] - ETA: 20:34 - loss: 0.2980
2736/8928 [========>.....................] - ETA: 20:30 - loss: 0.2966
2752/8928 [========>.....................] - ETA: 20:27 - loss: 0.2953
2768/8928 [========>.....................] - ETA: 20:24 - loss: 0.2940
2784/8928 [========>.....................] - ETA: 20:20 - loss: 0.2927
2800/8928 [========>.....................] - ETA: 20:17 - loss: 0.2914
2816/8928 [========>.....................] - ETA: 20:14 - loss: 0.2901
2832/8928 [========>.....................] - ETA: 20:11 - loss: 0.2889
2848/8928 [========>.....................] - ETA: 20:07 - loss: 0.2876
2864/8928 [========>.....................] - ETA: 20:04 - loss: 0.2864
2880/8928 [========>.....................] - ETA: 20:01 - loss: 0.2851
2896/8928 [========>.....................] - ETA: 19:57 - loss: 0.2839
2912/8928 [========>.....................] - ETA: 19:54 - loss: 0.2827
2928/8928 [========>.....................] - ETA: 19:51 - loss: 0.2815
2944/8928 [========>.....................] - ETA: 19:48 - loss: 0.2802
2960/8928 [========>.....................] - ETA: 19:44 - loss: 0.2791
2976/8928 [=========>....................] - ETA: 19:41 - loss: 0.2779
2992/8928 [=========>....................] - ETA: 19:38 - loss: 0.2767
3008/8928 [=========>....................] - ETA: 19:35 - loss: 0.2755
3024/8928 [=========>....................] - ETA: 19:31 - loss: 0.2744
3040/8928 [=========>....................] - ETA: 19:28 - loss: 0.2732
3056/8928 [=========>....................] - ETA: 19:25 - loss: 0.2721
3072/8928 [=========>....................] - ETA: 19:22 - loss: 0.2709
3088/8928 [=========>....................] - ETA: 19:18 - loss: 0.2698
3104/8928 [=========>....................] - ETA: 19:15 - loss: 0.2687
3120/8928 [=========>....................] - ETA: 19:12 - loss: 0.2676
3136/8928 [=========>....................] - ETA: 19:09 - loss: 0.2665
3152/8928 [=========>....................] - ETA: 19:05 - loss: 0.2654
3168/8928 [=========>....................] - ETA: 19:02 - loss: 0.2643
3184/8928 [=========>....................] - ETA: 18:59 - loss: 0.2632
3200/8928 [=========>....................] - ETA: 18:56 - loss: 0.2621
3216/8928 [=========>....................] - ETA: 18:52 - loss: 0.2611
3232/8928 [=========>....................] - ETA: 18:49 - loss: 0.2600
3248/8928 [=========>....................] - ETA: 18:46 - loss: 0.2590
3264/8928 [=========>....................] - ETA: 18:43 - loss: 0.2579
3280/8928 [==========>...................] - ETA: 18:39 - loss: 0.2569
3296/8928 [==========>...................] - ETA: 18:36 - loss: 0.2559
3312/8928 [==========>...................] - ETA: 18:33 - loss: 0.2548
3328/8928 [==========>...................] - ETA: 18:30 - loss: 0.2538
3344/8928 [==========>...................] - ETA: 18:26 - loss: 0.2528
3360/8928 [==========>...................] - ETA: 18:23 - loss: 0.2518
3376/8928 [==========>...................] - ETA: 18:20 - loss: 0.2508
3392/8928 [==========>...................] - ETA: 18:17 - loss: 0.2499
3408/8928 [==========>...................] - ETA: 18:13 - loss: 0.2489
3424/8928 [==========>...................] - ETA: 18:10 - loss: 0.2479
3440/8928 [==========>...................] - ETA: 18:07 - loss: 0.2469
3456/8928 [==========>...................] - ETA: 18:04 - loss: 0.2460
3472/8928 [==========>...................] - ETA: 18:01 - loss: 0.2450
3488/8928 [==========>...................] - ETA: 17:57 - loss: 0.2441
3504/8928 [==========>...................] - ETA: 17:54 - loss: 0.2432
3520/8928 [==========>...................] - ETA: 17:51 - loss: 0.2422
3536/8928 [==========>...................] - ETA: 17:48 - loss: 0.2413
3552/8928 [==========>...................] - ETA: 17:44 - loss: 0.2404
3568/8928 [==========>...................] - ETA: 17:41 - loss: 0.2395
3584/8928 [===========>..................] - ETA: 17:38 - loss: 0.2386
3600/8928 [===========>..................] - ETA: 17:35 - loss: 0.2377
3616/8928 [===========>..................] - ETA: 17:31 - loss: 0.2368
3632/8928 [===========>..................] - ETA: 17:28 - loss: 0.2359
3648/8928 [===========>..................] - ETA: 17:25 - loss: 0.2350
3664/8928 [===========>..................] - ETA: 17:22 - loss: 0.2341
3680/8928 [===========>..................] - ETA: 17:19 - loss: 0.2333
3696/8928 [===========>..................] - ETA: 17:15 - loss: 0.2324
3712/8928 [===========>..................] - ETA: 17:12 - loss: 0.2315
3728/8928 [===========>..................] - ETA: 17:09 - loss: 0.2307
3744/8928 [===========>..................] - ETA: 17:06 - loss: 0.2298
3760/8928 [===========>..................] - ETA: 17:03 - loss: 0.2290
3776/8928 [===========>..................] - ETA: 16:59 - loss: 0.2281
3792/8928 [===========>..................] - ETA: 16:56 - loss: 0.2273
3808/8928 [===========>..................] - ETA: 16:53 - loss: 0.2265
3824/8928 [===========>..................] - ETA: 16:50 - loss: 0.2257
3840/8928 [===========>..................] - ETA: 16:46 - loss: 0.2249
3856/8928 [===========>..................] - ETA: 16:43 - loss: 0.2241
3872/8928 [============>.................] - ETA: 16:40 - loss: 0.2232
3888/8928 [============>.................] - ETA: 16:37 - loss: 0.2224
3904/8928 [============>.................] - ETA: 16:34 - loss: 0.2217
3920/8928 [============>.................] - ETA: 16:30 - loss: 0.2209
3936/8928 [============>.................] - ETA: 16:27 - loss: 0.2201
3952/8928 [============>.................] - ETA: 16:24 - loss: 0.2193
3968/8928 [============>.................] - ETA: 16:21 - loss: 0.2185
3984/8928 [============>.................] - ETA: 16:18 - loss: 0.2178
4000/8928 [============>.................] - ETA: 16:14 - loss: 0.2170
4016/8928 [============>.................] - ETA: 16:11 - loss: 0.2162
4032/8928 [============>.................] - ETA: 16:08 - loss: 0.2155
4048/8928 [============>.................] - ETA: 16:05 - loss: 0.2147
4064/8928 [============>.................] - ETA: 16:02 - loss: 0.2140
4080/8928 [============>.................] - ETA: 15:58 - loss: 0.2133
4096/8928 [============>.................] - ETA: 15:55 - loss: 0.2125
4112/8928 [============>.................] - ETA: 15:52 - loss: 0.2118
4128/8928 [============>.................] - ETA: 15:49 - loss: 0.2111
4144/8928 [============>.................] - ETA: 15:46 - loss: 0.2103
4160/8928 [============>.................] - ETA: 15:42 - loss: 0.2096
4176/8928 [=============>................] - ETA: 15:39 - loss: 0.2089
4192/8928 [=============>................] - ETA: 15:36 - loss: 0.2082
4208/8928 [=============>................] - ETA: 15:33 - loss: 0.2075
4224/8928 [=============>................] - ETA: 15:30 - loss: 0.2068
4240/8928 [=============>................] - ETA: 15:26 - loss: 0.2061
4256/8928 [=============>................] - ETA: 15:23 - loss: 0.2054
4272/8928 [=============>................] - ETA: 15:20 - loss: 0.2047
4288/8928 [=============>................] - ETA: 15:17 - loss: 0.2040
4304/8928 [=============>................] - ETA: 15:14 - loss: 0.2034
4320/8928 [=============>................] - ETA: 15:10 - loss: 0.2027
4336/8928 [=============>................] - ETA: 15:07 - loss: 0.2020
4352/8928 [=============>................] - ETA: 15:04 - loss: 0.2014
4368/8928 [=============>................] - ETA: 15:01 - loss: 0.2007
4384/8928 [=============>................] - ETA: 14:58 - loss: 0.2000
4400/8928 [=============>................] - ETA: 14:54 - loss: 0.1994
4416/8928 [=============>................] - ETA: 14:51 - loss: 0.1987
4432/8928 [=============>................] - ETA: 14:48 - loss: 0.1981
4448/8928 [=============>................] - ETA: 14:45 - loss: 0.1975
4464/8928 [==============>...............] - ETA: 14:42 - loss: 0.1968
4480/8928 [==============>...............] - ETA: 14:39 - loss: 0.1962
4496/8928 [==============>...............] - ETA: 14:35 - loss: 0.1955
4512/8928 [==============>...............] - ETA: 14:32 - loss: 0.1949
4528/8928 [==============>...............] - ETA: 14:29 - loss: 0.1943
4544/8928 [==============>...............] - ETA: 14:26 - loss: 0.1937
4560/8928 [==============>...............] - ETA: 14:23 - loss: 0.1931
4576/8928 [==============>...............] - ETA: 14:19 - loss: 0.1925
4592/8928 [==============>...............] - ETA: 14:16 - loss: 0.1918
4608/8928 [==============>...............] - ETA: 14:13 - loss: 0.1912
4624/8928 [==============>...............] - ETA: 14:10 - loss: 0.1906
4640/8928 [==============>...............] - ETA: 14:07 - loss: 0.1900
4656/8928 [==============>...............] - ETA: 14:03 - loss: 0.1895
4672/8928 [==============>...............] - ETA: 14:00 - loss: 0.1889
4688/8928 [==============>...............] - ETA: 13:57 - loss: 0.1883
4704/8928 [==============>...............] - ETA: 13:54 - loss: 0.1877
4720/8928 [==============>...............] - ETA: 13:51 - loss: 0.1871
4736/8928 [==============>...............] - ETA: 13:48 - loss: 0.1865
4752/8928 [==============>...............] - ETA: 13:44 - loss: 0.1860
4768/8928 [===============>..............] - ETA: 13:41 - loss: 0.1854
4784/8928 [===============>..............] - ETA: 13:38 - loss: 0.1848
4800/8928 [===============>..............] - ETA: 13:35 - loss: 0.1843
4816/8928 [===============>..............] - ETA: 13:32 - loss: 0.1837
4832/8928 [===============>..............] - ETA: 13:28 - loss: 0.1831
4848/8928 [===============>..............] - ETA: 13:25 - loss: 0.1826
4864/8928 [===============>..............] - ETA: 13:22 - loss: 0.1820
4880/8928 [===============>..............] - ETA: 13:19 - loss: 0.1815
4896/8928 [===============>..............] - ETA: 13:16 - loss: 0.1810
4912/8928 [===============>..............] - ETA: 13:13 - loss: 0.1804
4928/8928 [===============>..............] - ETA: 13:09 - loss: 0.1799
4944/8928 [===============>..............] - ETA: 13:06 - loss: 0.1793
4960/8928 [===============>..............] - ETA: 13:03 - loss: 0.1788
4976/8928 [===============>..............] - ETA: 13:00 - loss: 0.1783
4992/8928 [===============>..............] - ETA: 12:57 - loss: 0.1778
5008/8928 [===============>..............] - ETA: 12:54 - loss: 0.1772
5024/8928 [===============>..............] - ETA: 12:50 - loss: 0.1767
5040/8928 [===============>..............] - ETA: 12:47 - loss: 0.1762
5056/8928 [===============>..............] - ETA: 12:44 - loss: 0.1757
5072/8928 [================>.............] - ETA: 12:41 - loss: 0.1752
5088/8928 [================>.............] - ETA: 12:38 - loss: 0.1747
5104/8928 [================>.............] - ETA: 12:34 - loss: 0.1742
5120/8928 [================>.............] - ETA: 12:31 - loss: 0.1736
5136/8928 [================>.............] - ETA: 12:28 - loss: 0.1731
5152/8928 [================>.............] - ETA: 12:25 - loss: 0.1726
5168/8928 [================>.............] - ETA: 12:22 - loss: 0.1722
5184/8928 [================>.............] - ETA: 12:19 - loss: 0.1717
5200/8928 [================>.............] - ETA: 12:15 - loss: 0.1712
5216/8928 [================>.............] - ETA: 12:12 - loss: 0.1707
5232/8928 [================>.............] - ETA: 12:09 - loss: 0.1702
5248/8928 [================>.............] - ETA: 12:06 - loss: 0.1697
5264/8928 [================>.............] - ETA: 12:03 - loss: 0.1692
5280/8928 [================>.............] - ETA: 12:00 - loss: 0.1688
5296/8928 [================>.............] - ETA: 11:56 - loss: 0.1683
5312/8928 [================>.............] - ETA: 11:53 - loss: 0.1678
5328/8928 [================>.............] - ETA: 11:50 - loss: 0.1674
5344/8928 [================>.............] - ETA: 11:47 - loss: 0.1669
5360/8928 [=================>............] - ETA: 11:44 - loss: 0.1664
5376/8928 [=================>............] - ETA: 11:41 - loss: 0.1660
5392/8928 [=================>............] - ETA: 11:37 - loss: 0.1655
5408/8928 [=================>............] - ETA: 11:34 - loss: 0.1651
5424/8928 [=================>............] - ETA: 11:31 - loss: 0.1646
5440/8928 [=================>............] - ETA: 11:28 - loss: 0.1641
5456/8928 [=================>............] - ETA: 11:25 - loss: 0.1637
5472/8928 [=================>............] - ETA: 11:21 - loss: 0.1633
5488/8928 [=================>............] - ETA: 11:18 - loss: 0.1628
5504/8928 [=================>............] - ETA: 11:15 - loss: 0.1624
5520/8928 [=================>............] - ETA: 11:12 - loss: 0.1619
5536/8928 [=================>............] - ETA: 11:09 - loss: 0.1615
5552/8928 [=================>............] - ETA: 11:06 - loss: 0.1611
5568/8928 [=================>............] - ETA: 11:02 - loss: 0.1606
5584/8928 [=================>............] - ETA: 10:59 - loss: 0.1602
5600/8928 [=================>............] - ETA: 10:56 - loss: 0.1598
5616/8928 [=================>............] - ETA: 10:53 - loss: 0.1593
5632/8928 [=================>............] - ETA: 10:50 - loss: 0.1589
5648/8928 [=================>............] - ETA: 10:47 - loss: 0.1585
5664/8928 [==================>...........] - ETA: 10:43 - loss: 0.1581
5680/8928 [==================>...........] - ETA: 10:40 - loss: 0.1577
5696/8928 [==================>...........] - ETA: 10:37 - loss: 0.1573
5712/8928 [==================>...........] - ETA: 10:34 - loss: 0.1568
5728/8928 [==================>...........] - ETA: 10:31 - loss: 0.1564
5744/8928 [==================>...........] - ETA: 10:28 - loss: 0.1560
5760/8928 [==================>...........] - ETA: 10:24 - loss: 0.1556
5776/8928 [==================>...........] - ETA: 10:21 - loss: 0.1552
5792/8928 [==================>...........] - ETA: 10:18 - loss: 0.1548
5808/8928 [==================>...........] - ETA: 10:15 - loss: 0.1544
5824/8928 [==================>...........] - ETA: 10:12 - loss: 0.1540
5840/8928 [==================>...........] - ETA: 10:09 - loss: 0.1536
5856/8928 [==================>...........] - ETA: 10:05 - loss: 0.1532
5872/8928 [==================>...........] - ETA: 10:02 - loss: 0.1528
5888/8928 [==================>...........] - ETA: 9:59 - loss: 0.1524 
5904/8928 [==================>...........] - ETA: 9:56 - loss: 0.1521
5920/8928 [==================>...........] - ETA: 9:53 - loss: 0.1517
5936/8928 [==================>...........] - ETA: 9:50 - loss: 0.1513
5952/8928 [===================>..........] - ETA: 9:46 - loss: 0.1509
5968/8928 [===================>..........] - ETA: 9:43 - loss: 0.1505
5984/8928 [===================>..........] - ETA: 9:40 - loss: 0.1502
6000/8928 [===================>..........] - ETA: 9:37 - loss: 0.1498
6016/8928 [===================>..........] - ETA: 9:34 - loss: 0.1494
6032/8928 [===================>..........] - ETA: 9:31 - loss: 0.1490
6048/8928 [===================>..........] - ETA: 9:27 - loss: 0.1487
6064/8928 [===================>..........] - ETA: 9:24 - loss: 0.1483
6080/8928 [===================>..........] - ETA: 9:21 - loss: 0.1479
6096/8928 [===================>..........] - ETA: 9:18 - loss: 0.1476
6112/8928 [===================>..........] - ETA: 9:15 - loss: 0.1472
6128/8928 [===================>..........] - ETA: 9:12 - loss: 0.1468
6144/8928 [===================>..........] - ETA: 9:08 - loss: 0.1465
6160/8928 [===================>..........] - ETA: 9:05 - loss: 0.1461
6176/8928 [===================>..........] - ETA: 9:02 - loss: 0.1458
6192/8928 [===================>..........] - ETA: 8:59 - loss: 0.1454
6208/8928 [===================>..........] - ETA: 8:56 - loss: 0.1451
6224/8928 [===================>..........] - ETA: 8:53 - loss: 0.1447
6240/8928 [===================>..........] - ETA: 8:49 - loss: 0.1444
6256/8928 [====================>.........] - ETA: 8:46 - loss: 0.1440
6272/8928 [====================>.........] - ETA: 8:43 - loss: 0.1437
6288/8928 [====================>.........] - ETA: 8:40 - loss: 0.1433
6304/8928 [====================>.........] - ETA: 8:37 - loss: 0.1430
6320/8928 [====================>.........] - ETA: 8:34 - loss: 0.1426
6336/8928 [====================>.........] - ETA: 8:30 - loss: 0.1423
6352/8928 [====================>.........] - ETA: 8:27 - loss: 0.1420
6368/8928 [====================>.........] - ETA: 8:24 - loss: 0.1416
6384/8928 [====================>.........] - ETA: 8:21 - loss: 0.1413
6400/8928 [====================>.........] - ETA: 8:18 - loss: 0.1410
6416/8928 [====================>.........] - ETA: 8:15 - loss: 0.1406
6432/8928 [====================>.........] - ETA: 8:11 - loss: 0.1403
6448/8928 [====================>.........] - ETA: 8:08 - loss: 0.1400
6464/8928 [====================>.........] - ETA: 8:05 - loss: 0.1396
6480/8928 [====================>.........] - ETA: 8:02 - loss: 0.1393
6496/8928 [====================>.........] - ETA: 7:59 - loss: 0.1390
6512/8928 [====================>.........] - ETA: 7:56 - loss: 0.1387
6528/8928 [====================>.........] - ETA: 7:52 - loss: 0.1384
6544/8928 [====================>.........] - ETA: 7:49 - loss: 0.1380
6560/8928 [=====================>........] - ETA: 7:46 - loss: 0.1377
6576/8928 [=====================>........] - ETA: 7:43 - loss: 0.1374
6592/8928 [=====================>........] - ETA: 7:40 - loss: 0.1371
6608/8928 [=====================>........] - ETA: 7:37 - loss: 0.1368
6624/8928 [=====================>........] - ETA: 7:34 - loss: 0.1365
6640/8928 [=====================>........] - ETA: 7:30 - loss: 0.1362
6656/8928 [=====================>........] - ETA: 7:27 - loss: 0.1358
6672/8928 [=====================>........] - ETA: 7:24 - loss: 0.1355
6688/8928 [=====================>........] - ETA: 7:21 - loss: 0.1352
6704/8928 [=====================>........] - ETA: 7:18 - loss: 0.1349
6720/8928 [=====================>........] - ETA: 7:15 - loss: 0.1346
6736/8928 [=====================>........] - ETA: 7:11 - loss: 0.1343
6752/8928 [=====================>........] - ETA: 7:08 - loss: 0.1340
6768/8928 [=====================>........] - ETA: 7:05 - loss: 0.1337
6784/8928 [=====================>........] - ETA: 7:02 - loss: 0.1334
6800/8928 [=====================>........] - ETA: 6:59 - loss: 0.1331
6816/8928 [=====================>........] - ETA: 6:56 - loss: 0.1328
6832/8928 [=====================>........] - ETA: 6:52 - loss: 0.1325
6848/8928 [======================>.......] - ETA: 6:49 - loss: 0.1323
6864/8928 [======================>.......] - ETA: 6:46 - loss: 0.1320
6880/8928 [======================>.......] - ETA: 6:43 - loss: 0.1317
6896/8928 [======================>.......] - ETA: 6:40 - loss: 0.1314
6912/8928 [======================>.......] - ETA: 6:37 - loss: 0.1311
6928/8928 [======================>.......] - ETA: 6:34 - loss: 0.1308
6944/8928 [======================>.......] - ETA: 6:30 - loss: 0.1305
6960/8928 [======================>.......] - ETA: 6:27 - loss: 0.1302
6976/8928 [======================>.......] - ETA: 6:24 - loss: 0.1300
6992/8928 [======================>.......] - ETA: 6:21 - loss: 0.1297
7008/8928 [======================>.......] - ETA: 6:18 - loss: 0.1294
7024/8928 [======================>.......] - ETA: 6:15 - loss: 0.1291
7040/8928 [======================>.......] - ETA: 6:11 - loss: 0.1288
7056/8928 [======================>.......] - ETA: 6:08 - loss: 0.1286
7072/8928 [======================>.......] - ETA: 6:05 - loss: 0.1283
7088/8928 [======================>.......] - ETA: 6:02 - loss: 0.1280
7104/8928 [======================>.......] - ETA: 5:59 - loss: 0.1277
7120/8928 [======================>.......] - ETA: 5:56 - loss: 0.1275
7136/8928 [======================>.......] - ETA: 5:52 - loss: 0.1272
7152/8928 [=======================>......] - ETA: 5:49 - loss: 0.1269
7168/8928 [=======================>......] - ETA: 5:46 - loss: 0.1267
7184/8928 [=======================>......] - ETA: 5:43 - loss: 0.1264
7200/8928 [=======================>......] - ETA: 5:40 - loss: 0.1261
7216/8928 [=======================>......] - ETA: 5:37 - loss: 0.1259
7232/8928 [=======================>......] - ETA: 5:34 - loss: 0.1256
7248/8928 [=======================>......] - ETA: 5:30 - loss: 0.1254
7264/8928 [=======================>......] - ETA: 5:27 - loss: 0.1251
7280/8928 [=======================>......] - ETA: 5:24 - loss: 0.1248
7296/8928 [=======================>......] - ETA: 5:21 - loss: 0.1246
7312/8928 [=======================>......] - ETA: 5:18 - loss: 0.1243
7328/8928 [=======================>......] - ETA: 5:15 - loss: 0.1241
7344/8928 [=======================>......] - ETA: 5:11 - loss: 0.1238
7360/8928 [=======================>......] - ETA: 5:08 - loss: 0.1236
7376/8928 [=======================>......] - ETA: 5:05 - loss: 0.1233
7392/8928 [=======================>......] - ETA: 5:02 - loss: 0.1230
7408/8928 [=======================>......] - ETA: 4:59 - loss: 0.1228
7424/8928 [=======================>......] - ETA: 4:56 - loss: 0.1225
7440/8928 [========================>.....] - ETA: 4:53 - loss: 0.1223
7456/8928 [========================>.....] - ETA: 4:49 - loss: 0.1221
7472/8928 [========================>.....] - ETA: 4:46 - loss: 0.1218
7488/8928 [========================>.....] - ETA: 4:43 - loss: 0.1216
7504/8928 [========================>.....] - ETA: 4:40 - loss: 0.1213
7520/8928 [========================>.....] - ETA: 4:37 - loss: 0.1211
7536/8928 [========================>.....] - ETA: 4:34 - loss: 0.1208
7552/8928 [========================>.....] - ETA: 4:30 - loss: 0.1206
7568/8928 [========================>.....] - ETA: 4:27 - loss: 0.1203
7584/8928 [========================>.....] - ETA: 4:24 - loss: 0.1201
7600/8928 [========================>.....] - ETA: 4:21 - loss: 0.1199
7616/8928 [========================>.....] - ETA: 4:18 - loss: 0.1196
7632/8928 [========================>.....] - ETA: 4:15 - loss: 0.1194
7648/8928 [========================>.....] - ETA: 4:12 - loss: 0.1192
7664/8928 [========================>.....] - ETA: 4:08 - loss: 0.1189
7680/8928 [========================>.....] - ETA: 4:05 - loss: 0.1187
7696/8928 [========================>.....] - ETA: 4:02 - loss: 0.1185
7712/8928 [========================>.....] - ETA: 3:59 - loss: 0.1182
7728/8928 [========================>.....] - ETA: 3:56 - loss: 0.1180
7744/8928 [=========================>....] - ETA: 3:53 - loss: 0.1178
7760/8928 [=========================>....] - ETA: 3:49 - loss: 0.1175
7776/8928 [=========================>....] - ETA: 3:46 - loss: 0.1173
7792/8928 [=========================>....] - ETA: 3:43 - loss: 0.1171
7808/8928 [=========================>....] - ETA: 3:40 - loss: 0.1169
7824/8928 [=========================>....] - ETA: 3:37 - loss: 0.1166
7840/8928 [=========================>....] - ETA: 3:34 - loss: 0.1164
7856/8928 [=========================>....] - ETA: 3:31 - loss: 0.1162
7872/8928 [=========================>....] - ETA: 3:27 - loss: 0.1160
7888/8928 [=========================>....] - ETA: 3:24 - loss: 0.1157
7904/8928 [=========================>....] - ETA: 3:21 - loss: 0.1155
7920/8928 [=========================>....] - ETA: 3:18 - loss: 0.1153
7936/8928 [=========================>....] - ETA: 3:15 - loss: 0.1151
7952/8928 [=========================>....] - ETA: 3:12 - loss: 0.1149
7968/8928 [=========================>....] - ETA: 3:08 - loss: 0.1146
7984/8928 [=========================>....] - ETA: 3:05 - loss: 0.1144
8000/8928 [=========================>....] - ETA: 3:02 - loss: 0.1142
8016/8928 [=========================>....] - ETA: 2:59 - loss: 0.1140
8032/8928 [=========================>....] - ETA: 2:56 - loss: 0.1138
8048/8928 [==========================>...] - ETA: 2:53 - loss: 0.1136
8064/8928 [==========================>...] - ETA: 2:50 - loss: 0.1134
8080/8928 [==========================>...] - ETA: 2:46 - loss: 0.1132
8096/8928 [==========================>...] - ETA: 2:43 - loss: 0.1129
8112/8928 [==========================>...] - ETA: 2:40 - loss: 0.1127
8128/8928 [==========================>...] - ETA: 2:37 - loss: 0.1125
8144/8928 [==========================>...] - ETA: 2:34 - loss: 0.1123
8160/8928 [==========================>...] - ETA: 2:31 - loss: 0.1121
8176/8928 [==========================>...] - ETA: 2:28 - loss: 0.1119
8192/8928 [==========================>...] - ETA: 2:24 - loss: 0.1117
8208/8928 [==========================>...] - ETA: 2:21 - loss: 0.1115
8224/8928 [==========================>...] - ETA: 2:18 - loss: 0.1113
8240/8928 [==========================>...] - ETA: 2:15 - loss: 0.1111
8256/8928 [==========================>...] - ETA: 2:12 - loss: 0.1109
8272/8928 [==========================>...] - ETA: 2:09 - loss: 0.1107
8288/8928 [==========================>...] - ETA: 2:05 - loss: 0.1105
8304/8928 [==========================>...] - ETA: 2:02 - loss: 0.1103
8320/8928 [==========================>...] - ETA: 1:59 - loss: 0.1101
8336/8928 [===========================>..] - ETA: 1:56 - loss: 0.1099
8352/8928 [===========================>..] - ETA: 1:53 - loss: 0.1097
8368/8928 [===========================>..] - ETA: 1:50 - loss: 0.1095
8384/8928 [===========================>..] - ETA: 1:47 - loss: 0.1093
8400/8928 [===========================>..] - ETA: 1:43 - loss: 0.1091
8416/8928 [===========================>..] - ETA: 1:40 - loss: 0.1089
8432/8928 [===========================>..] - ETA: 1:37 - loss: 0.1087
8448/8928 [===========================>..] - ETA: 1:34 - loss: 0.1085
8464/8928 [===========================>..] - ETA: 1:31 - loss: 0.1083
8480/8928 [===========================>..] - ETA: 1:28 - loss: 0.1081
8496/8928 [===========================>..] - ETA: 1:25 - loss: 0.1079
8512/8928 [===========================>..] - ETA: 1:21 - loss: 0.1077
8528/8928 [===========================>..] - ETA: 1:18 - loss: 0.1075
8544/8928 [===========================>..] - ETA: 1:15 - loss: 0.1074
8560/8928 [===========================>..] - ETA: 1:12 - loss: 0.1072
8576/8928 [===========================>..] - ETA: 1:09 - loss: 0.1070
8592/8928 [===========================>..] - ETA: 1:06 - loss: 0.1068
8608/8928 [===========================>..] - ETA: 1:02 - loss: 0.1066
8624/8928 [===========================>..] - ETA: 59s - loss: 0.1064 
8640/8928 [============================>.] - ETA: 56s - loss: 0.1062
8656/8928 [============================>.] - ETA: 53s - loss: 0.1060
8672/8928 [============================>.] - ETA: 50s - loss: 0.1059
8688/8928 [============================>.] - ETA: 47s - loss: 0.1057
8704/8928 [============================>.] - ETA: 44s - loss: 0.1055
8720/8928 [============================>.] - ETA: 40s - loss: 0.1053
8736/8928 [============================>.] - ETA: 37s - loss: 0.1051
8752/8928 [============================>.] - ETA: 34s - loss: 0.1049
8768/8928 [============================>.] - ETA: 31s - loss: 0.1048
8784/8928 [============================>.] - ETA: 28s - loss: 0.1046
8800/8928 [============================>.] - ETA: 25s - loss: 0.1044
8816/8928 [============================>.] - ETA: 22s - loss: 0.1042
8832/8928 [============================>.] - ETA: 18s - loss: 0.1041
8848/8928 [============================>.] - ETA: 15s - loss: 0.1039
8864/8928 [============================>.] - ETA: 12s - loss: 0.1037
8880/8928 [============================>.] - ETA: 9s - loss: 0.1035 
8896/8928 [============================>.] - ETA: 6s - loss: 0.1033
8912/8928 [============================>.] - ETA: 3s - loss: 0.1032
8928/8928 [==============================] - 1774s 199ms/step - loss: 0.1030 - val_loss: 0.0053
/scratch/user/narendra5/.conda/envs/deeplearning/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
Using TensorFlow backend.
/scratch/user/narendra5/LER_machine_learning/neural_nets/multi_gpu.py:45: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.
  merged.append(merge(outputs, mode='concat', concat_axis=0))
/scratch/user/narendra5/.conda/envs/deeplearning/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.
  name=name)
/scratch/user/narendra5/LER_machine_learning/neural_nets/multi_gpu.py:47: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`
  return Model(input=model.inputs, output=merged)
Execttion Time=  1831.9840269088745
[0.1029980303594462]
[0.0053498984650812214]
